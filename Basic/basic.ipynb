{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyoje\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist, cifar10\n",
    "(img_train, label_train), (img_test, label_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv_block(inputs, filters, scope_num):\n",
    "    with tf.variable_scope('{}/conv_layer'.format(model, scope_num)):\n",
    "        conv = tf.layers.conv2d(inputs=inputs, filters=filters, kernel_size=[3, 3], \n",
    "                                padding='SAME', activation=tf.nn.relu, \n",
    "                                name='conv{}'.format(scope_num))\n",
    "        pool = tf.layers.max_pooling2d(inputs=conv, pool_size=[2, 2], \n",
    "                                       padding='SAME', strides=2, \n",
    "                                       name='pool{}'.format(scope_num))\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(sess, logits, img, label, batch_size):    \n",
    "    if len(img) < batch_size:\n",
    "        logit = sess.run(logits, feed_dict={X: img, training: False})\n",
    "    else:\n",
    "        total_batch = np.ceil((len(img) / batch_size)).astype(np.int32)\n",
    "        num_classes = int(logits.shape[-1])\n",
    "        logit = np.array([], dtype=np.int64).reshape(0, num_classes)\n",
    "        idxs = range(len(img))\n",
    "        for i in range(total_batch):\n",
    "            idxs_i = idxs[i * batch_size : (i + 1) * batch_size]\n",
    "            feed_dict = {X: img[idxs_i], training: False}\n",
    "            logit = np.concatenate((logit, sess.run(logits, feed_dict=feed_dict)), axis=0)\n",
    "\n",
    "    correct_pred = np.equal(np.argmax(logit, 1), label).astype(np.float32)\n",
    "    accuracy = np.mean(correct_pred)\n",
    "    \n",
    "    return accuracy, logit, correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'basic'\n",
    "img_row, img_col = img_train.shape[1], img_train.shape[2]\n",
    "img_depth = 1\n",
    "\n",
    "img_train = img_train.reshape(img_train.shape[0], img_row, img_col, img_depth)\n",
    "img_test = img_test.reshape(img_test.shape[0], img_row, img_col, img_depth)\n",
    "img_train = img_train.astype('float32')\n",
    "img_test = img_test.astype('float32')\n",
    "img_train /= 255\n",
    "img_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, img_row, img_col, img_depth])\n",
    "Y = tf.placeholder(tf.int64, [None])\n",
    "training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build network\n",
    "# convolution layers\n",
    "\n",
    "block1 = Conv_block(inputs=X, filters=32, scope_num=1)\n",
    "block2 = Conv_block(inputs=block1, filters=32, scope_num=2)\n",
    "conv = Conv_block(inputs=block2, filters=32, scope_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected layers\n",
    "\n",
    "flat_num = int(conv.shape[1] * conv.shape[2] * conv.shape[3])\n",
    "flat = tf.reshape(conv, [-1, flat_num])\n",
    "\n",
    "with tf.variable_scope('{}/fc_layer'.format(model)):\n",
    "    dense1 = tf.layers.dense(inputs=flat, units=512, \n",
    "                            activation=tf.nn.relu, name='dense1')\n",
    "    drop1 = tf.layers.dropout(inputs=dense1, rate=0.25, training=training)\n",
    "    dense2 = tf.layers.dense(inputs=drop1, units=512, \n",
    "                            activation=tf.nn.relu, name='dense2')\n",
    "    drop2 = tf.layers.dropout(inputs=dense2, rate=0.25, training=training)\n",
    "    logits = tf.layers.dense(inputs=drop2, units=10, name='logit')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper prameter\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "CHECK_POINT_DIR = './save_model'\n",
    "IS_SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=tf.ConfigProto(allow_soft_placement=True)\n",
    "#config.gpu_options.allocator_type='BFC'\n",
    "config.log_device_placement=False\n",
    "config.gpu_options.allow_growth=True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do not save\n"
     ]
    }
   ],
   "source": [
    "# Restore and Save\n",
    "if IS_SAVE:\n",
    "    saver = tf.train.Saver()\n",
    "    checkpoint = tf.train.get_checkpoint_state(CHECK_POINT_DIR)\n",
    "\n",
    "    if checkpoint and checkpoint.model_checkpoint_path:\n",
    "        try:\n",
    "            saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "            print(\"Successfully loaded:\", checkpoint.model_checkpoint_path)\n",
    "        except:\n",
    "            print(\"Error on loading old network weights\")\n",
    "    else:\n",
    "        print(\"Could not find old network weights\")\n",
    "else:\n",
    "    print('Do not save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 21 20:08:52 2018\n",
      "Batch size : 128, Epochs : 5, Save_dir : ./save_model\n",
      "Learning Started.\n",
      "=====================================\n",
      "Epoch : 01 , Cost : 0.23487\n",
      "Train Accuracy : 0.97925\n",
      "Test Accuracy : 0.97920\n",
      "Elapsed time of an epoch: 14.73200\n",
      "===========Best accuracy=============\n",
      "Mon May 21 20:09:07 2018\n",
      "Best Accuracy : 0.97920\n",
      "Elapsed time to get the best accuracy: 14.73300\n",
      "=====================================\n",
      "Epoch : 02 , Cost : 0.06431\n",
      "Train Accuracy : 0.98847\n",
      "Test Accuracy : 0.98720\n",
      "Elapsed time of an epoch: 13.77064\n",
      "===========Best accuracy=============\n",
      "Mon May 21 20:09:21 2018\n",
      "Best Accuracy : 0.98720\n",
      "Elapsed time to get the best accuracy: 28.50364\n",
      "=====================================\n",
      "Epoch : 03 , Cost : 0.04449\n",
      "Train Accuracy : 0.99327\n",
      "Test Accuracy : 0.98940\n",
      "Elapsed time of an epoch: 13.39765\n",
      "===========Best accuracy=============\n",
      "Mon May 21 20:09:34 2018\n",
      "Best Accuracy : 0.98940\n",
      "Elapsed time to get the best accuracy: 41.90130\n",
      "=====================================\n",
      "Epoch : 04 , Cost : 0.03541\n",
      "Train Accuracy : 0.99255\n",
      "Test Accuracy : 0.98940\n",
      "Elapsed time of an epoch: 13.86289\n",
      "=====================================\n",
      "Epoch : 05 , Cost : 0.03100\n",
      "Train Accuracy : 0.99457\n",
      "Test Accuracy : 0.98940\n",
      "Elapsed time of an epoch: 13.71750\n",
      "=====================================\n",
      "Final Test Accuracy : 0.98940\n",
      "Total elapsed time: 69.48169\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "print(time.asctime())\n",
    "print('Batch size : {}, Epochs : {}, Save_dir : {}'.format(BATCH_SIZE, EPOCHS, CHECK_POINT_DIR))\n",
    "print('Learning Started.')\n",
    "\n",
    "total_start = time.time()\n",
    "max_accuracy = 0.0\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    avg_cost = 0\n",
    "    total_batch = np.ceil(img_train.shape[0] / BATCH_SIZE).astype(np.int32)\n",
    "    \n",
    "    idxs = np.random.permutation(range(len(img_train)))\n",
    "    for i in range(total_batch):\n",
    "        idxs_i = idxs[i * BATCH_SIZE : (i + 1) * BATCH_SIZE]\n",
    "        feed_dict = {X: img_train[idxs_i], Y: label_train[idxs_i], training: True }    \n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    print('=====================================')\n",
    "    print('Epoch : {:02d} , Cost : {:.5f}'.format(epoch + 1, avg_cost))\n",
    "    train_accuracy, _, _ = get_accuracy(sess, logits, img_train, label_train, BATCH_SIZE)\n",
    "    print('Train Accuracy : {:.5f}'.format(train_accuracy))\n",
    "    test_accuracy, _, _ = get_accuracy(sess, logits, img_test, label_test, BATCH_SIZE)\n",
    "    print('Test Accuracy : {:.5f}'.format(test_accuracy))\n",
    "    print('Elapsed time of an epoch: {:.5f}'.format(time.time() - epoch_start))\n",
    "    if test_accuracy > max_accuracy:\n",
    "        max_accuracy = test_accuracy\n",
    "        print('===========Best accuracy=============')\n",
    "        print(time.asctime())\n",
    "        print('Best Accuracy : {:.5f}'.format(max_accuracy))\n",
    "        print('Elapsed time to get the best accuracy: {:.5f}'.format(time.time() - total_start))\n",
    "        if IS_SAVE:\n",
    "            print('===========Saving network with the best accuracy===========')\n",
    "            if not os.path.exists(CHECK_POINT_DIR):\n",
    "                os.makedirs(CHECK_POINT_DIR)\n",
    "            saver.save(sess, CHECK_POINT_DIR + \"/model\", global_step=epoch+1)\n",
    "\n",
    "print('=====================================')\n",
    "\n",
    "print('Final Test Accuracy : {:.5f}'.format(max_accuracy))\n",
    "print('Total elapsed time: {:.5f}'.format(time.time() - total_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
