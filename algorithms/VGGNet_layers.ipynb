{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hyoje\\Anaconda3\\envs\\tfgpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(img_train, label_train), (img_test, label_test) = cifar10.load_data()\n",
    "\n",
    "img_row, img_col = img_train.shape[1], img_train.shape[2]\n",
    "#img_depth = 1\n",
    "img_depth = img_train.shape[3]\n",
    "\n",
    "#img_train = img_train.reshape(img_train.shape[0], img_row, img_col, img_depth)\n",
    "#img_test = img_test.reshape(img_test.shape[0], img_row, img_col, img_depth)\n",
    "label_train = np.squeeze(label_train, axis=-1)\n",
    "label_test = np.squeeze(label_test, axis=-1)\n",
    "img_train = img_train.astype('float32')\n",
    "img_test = img_test.astype('float32')\n",
    "img_train /= 255\n",
    "img_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(inputs, filters, name):\n",
    "    with tf.variable_scope('{}/conv_layer'.format(model)):\n",
    "        conv = tf.layers.conv2d(inputs=inputs, filters=filters, kernel_size=[3, 3],\n",
    "                                strides=[1, 1], padding='same', name=name)\n",
    "    return conv\n",
    "\n",
    "def max_pool(inputs, name):\n",
    "    with tf.variable_scope('{}/conv_layer'.format(model)):\n",
    "        pool = tf.layers.max_pooling2d(inputs=inputs, strides=[2, 2], pool_size=[2, 2],\n",
    "                                       padding='same', name=name)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(sess, logits, img, label, batch_size):    \n",
    "    if len(img) < batch_size:\n",
    "        logit = sess.run(logits, feed_dict={X: img, keep_prob: 1.0})\n",
    "    else:\n",
    "        total_batch = int(len(img) / batch_size) + 1\n",
    "        num_label = int(logits.shape[-1])\n",
    "        logit = np.array([], dtype=np.int64).reshape(0, num_label)\n",
    "        idxs = range(len(img))\n",
    "        for i in range(total_batch):\n",
    "            if i < (total_batch - 1):\n",
    "                idxs_i = idxs[i * batch_size : (i + 1) * batch_size]\n",
    "            else:\n",
    "                idxs_i = idxs[i * batch_size : len(img)]\n",
    "            feed_dict = {X: img[idxs_i], keep_prob: 1.0}\n",
    "            logit = np.concatenate((logit, sess.run(logits, feed_dict=feed_dict)), axis=0)\n",
    "\n",
    "    correct_pred = np.equal(np.argmax(logit, 1), label).astype(np.float32)\n",
    "    accuracy = np.mean(correct_pred)\n",
    "    \n",
    "    return accuracy, logit, correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper prameter\n",
    "model = 'VGGNet16'\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "CHECK_POINT_DIR = './save_model_{}'.format(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, img_row, img_col, img_depth])\n",
    "Y = tf.placeholder(tf.int64, [None])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16\n",
    "\n",
    "# convolution layers\n",
    "\n",
    "conv1 = conv_layer(inputs=X, filters=64, name='conv1')\n",
    "conv2 = conv_layer(inputs=conv1, filters=64, name='conv2')\n",
    "max1 = max_pool(inputs=conv2, name='max1')\n",
    "\n",
    "conv3 = conv_layer(inputs=max1, filters=128, name='conv3')\n",
    "conv4 = conv_layer(inputs=conv3, filters=128, name='conv4')\n",
    "max2 = max_pool(inputs=conv4, name='max2')\n",
    "\n",
    "conv5 = conv_layer(inputs=max2, filters=256, name='conv5')\n",
    "conv6 = conv_layer(inputs=conv5, filters=256, name='conv6')\n",
    "conv7 = conv_layer(inputs=conv6, filters=256, name='conv7')\n",
    "max3 = max_pool(inputs=conv7, name='max3')\n",
    "\n",
    "conv8 = conv_layer(inputs=max3, filters=512, name='conv8')\n",
    "conv9 = conv_layer(inputs=conv8, filters=512, name='conv9')\n",
    "conv10 = conv_layer(inputs=conv9, filters=512, name='conv10')\n",
    "max4 = max_pool(inputs=conv10, name='max4')\n",
    "\n",
    "conv11 = conv_layer(inputs=max4, filters=512, name='conv11')\n",
    "conv12 = conv_layer(inputs=conv11, filters=512, name='conv12')\n",
    "conv13 = conv_layer(inputs=conv12, filters=512, name='conv13')\n",
    "max5 = max_pool(inputs=conv13, name='max5')\n",
    "\n",
    "conv = max5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected layers\n",
    "\n",
    "flat_num = int(conv.shape[1] * conv.shape[2] * conv.shape[3])\n",
    "flat = tf.reshape(conv, [-1, flat_num])\n",
    "\n",
    "with tf.variable_scope('{}/fc_layer'.format(model)):\n",
    "    dense1 = tf.layers.dense(inputs=flat, units=4096, \n",
    "                            activation=tf.nn.relu, name='dense1')\n",
    "    drop1 = tf.nn.dropout(x=dense1, keep_prob=keep_prob)\n",
    "    dense2 = tf.layers.dense(inputs=drop1, units=4096, \n",
    "                            activation=tf.nn.relu, name='dense2')\n",
    "    drop2 = tf.nn.dropout(x=dense2, keep_prob=keep_prob)\n",
    "    logits = tf.layers.dense(inputs=drop2, units=10, name='logit')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(33638218)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([np.prod(v.shape) for v in tf.trainable_variables()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config=tf.ConfigProto(allow_soft_placement=True)\n",
    "#config.gpu_options.allocator_type='BFC'\n",
    "config.log_device_placement=False\n",
    "config.gpu_options.allow_growth=True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find old network weights\n"
     ]
    }
   ],
   "source": [
    "# Restore and Save\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "checkpoint = tf.train.get_checkpoint_state(CHECK_POINT_DIR)\n",
    "\n",
    "if checkpoint and checkpoint.model_checkpoint_path:\n",
    "    epoch_num = int(checkpoint.model_checkpoint_path.split('-')[-1]) + 1\n",
    "    max_accuracy, _, _= get_accuracy(sess, logits, img_test, label_test, batch_size)\n",
    "    try:\n",
    "        saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "        print(\"Successfully loaded:\", checkpoint.model_checkpoint_path)\n",
    "    except:\n",
    "        print(\"Error on loading old network weights\")\n",
    "else:\n",
    "    epoch_num = 1\n",
    "    max_accuracy = 0.0\n",
    "    print(\"Could not find old network weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 31 15:15:33 2018\n",
      "Learning Started.\n",
      "=====================================\n",
      "Epoch : 01 , Cost : 2.85063\n",
      "Train Accuracy : 0.34646\n",
      "Test Accuracy : 0.34870\n",
      "Elapsed time of an epoch: 142.28625\n",
      "===========Saving network with the best accuracy===========\n",
      "=====================================\n",
      "Epoch : 02 , Cost : 1.59873\n",
      "Train Accuracy : 0.48180\n",
      "Test Accuracy : 0.47130\n",
      "Elapsed time of an epoch: 140.34008\n",
      "===========Saving network with the best accuracy===========\n",
      "=====================================\n",
      "Epoch : 03 , Cost : 1.33612\n",
      "Train Accuracy : 0.61064\n",
      "Test Accuracy : 0.59430\n",
      "Elapsed time of an epoch: 141.00885\n",
      "===========Saving network with the best accuracy===========\n",
      "=====================================\n",
      "Epoch : 04 , Cost : 1.13290\n",
      "Train Accuracy : 0.64296\n",
      "Test Accuracy : 0.61080\n",
      "Elapsed time of an epoch: 140.37392\n",
      "===========Saving network with the best accuracy===========\n",
      "=====================================\n",
      "Epoch : 05 , Cost : 1.01777\n",
      "Train Accuracy : 0.67684\n",
      "Test Accuracy : 0.63520\n",
      "Elapsed time of an epoch: 139.19032\n",
      "===========Saving network with the best accuracy===========\n",
      "=====================================\n",
      "Epoch : 06 , Cost : 0.95414\n",
      "Train Accuracy : 0.72600\n",
      "Test Accuracy : 0.67060\n",
      "Elapsed time of an epoch: 137.70633\n",
      "===========Saving network with the best accuracy===========\n",
      "=====================================\n",
      "Epoch : 07 , Cost : 0.92383\n",
      "Train Accuracy : 0.70476\n",
      "Test Accuracy : 0.65820\n",
      "Elapsed time of an epoch: 137.88884\n",
      "=====================================\n",
      "Epoch : 08 , Cost : 0.94490\n",
      "Train Accuracy : 0.73178\n",
      "Test Accuracy : 0.67410\n",
      "Elapsed time of an epoch: 141.29956\n",
      "===========Saving network with the best accuracy===========\n",
      "=====================================\n",
      "Epoch : 09 , Cost : 1.02528\n",
      "Train Accuracy : 0.62818\n",
      "Test Accuracy : 0.58180\n",
      "Elapsed time of an epoch: 140.54193\n",
      "=====================================\n",
      "Epoch : 10 , Cost : 25762757.72157\n",
      "Train Accuracy : 0.10000\n",
      "Test Accuracy : 0.10000\n",
      "Elapsed time of an epoch: 137.27165\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "print(time.asctime())\n",
    "print ('Learning Started.')\n",
    "\n",
    "total_start = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "    avg_cost = 0\n",
    "    total_batch = int(img_train.shape[0] / batch_size) + 1\n",
    "    \n",
    "    idxs = np.random.permutation(range(len(img_train)))\n",
    "    for i in range(total_batch):\n",
    "        if i < (total_batch - 1):        \n",
    "            idxs_i = idxs[i * batch_size : (i + 1) * batch_size]\n",
    "        else:\n",
    "            idxs_i = idxs[i * batch_size : len(img_train)]\n",
    "            \n",
    "        feed_dict = {X: img_train[idxs_i], Y: label_train[idxs_i], keep_prob: 0.5}    \n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    print ('=====================================')\n",
    "    print ('Epoch : {:02d} , Cost : {:.5f}'.format(epoch + epoch_num, avg_cost))\n",
    "    train_accuracy, _, _ = get_accuracy(sess, logits, img_train, label_train, batch_size)\n",
    "    print ('Train Accuracy : {:.5f}'.format(train_accuracy))\n",
    "    test_accuracy, _, _ = get_accuracy(sess, logits, img_test, label_test, batch_size)\n",
    "    print ('Test Accuracy : {:.5f}'.format(test_accuracy))\n",
    "    print ('Elapsed time of an epoch: {:.5f}'.format(time.time() - epoch_start))\n",
    "    if test_accuracy > max_accuracy:\n",
    "        max_accuracy = test_accuracy\n",
    "        print ('===========Saving network with the best accuracy===========')\n",
    "        if not os.path.exists(CHECK_POINT_DIR):\n",
    "            os.makedirs(CHECK_POINT_DIR)\n",
    "        saver.save(sess, CHECK_POINT_DIR + \"/model\", global_step=epoch+epoch_num)\n",
    "\n",
    "print ('=====================================')\n",
    "\n",
    "print ('Final Test Accuracy : {:.5f}'.format(max_accuracy))\n",
    "print ('Total elapsed time: {:.5f}'.format(time.time() - total_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
