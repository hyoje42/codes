{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist, cifar10\n",
    "(img_train, label_train), (img_test, label_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv_block(inputs, filters, scope_num):\n",
    "    with tf.variable_scope('{}/conv_layer'.format(model, scope_num)):\n",
    "        conv = tf.layers.conv2d(inputs=inputs, filters=filters, kernel_size=[3, 3], \n",
    "                                padding='SAME', activation=tf.nn.relu, \n",
    "                                name='conv{}'.format(scope_num))\n",
    "        pool = tf.layers.max_pooling2d(inputs=conv, pool_size=[2, 2], \n",
    "                                       padding='SAME', strides=2, \n",
    "                                       name='pool{}'.format(scope_num))\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(sess, logits, img, label, batch_size):    \n",
    "    if len(img) < batch_size:\n",
    "        logit = sess.run(logits, feed_dict={X: img, training: False})\n",
    "    else:\n",
    "        total_batch = int(len(img) / batch_size) + 1\n",
    "        num_label = int(logits.shape[-1])\n",
    "        logit = np.array([], dtype=np.int64).reshape(0, num_label)\n",
    "        idxs = range(len(img))\n",
    "        for i in range(total_batch):\n",
    "            if i < (total_batch - 1):\n",
    "                idxs_i = idxs[i * batch_size : (i + 1) * batch_size]\n",
    "            else:\n",
    "                idxs_i = idxs[i * batch_size : len(img)]\n",
    "            feed_dict = {X: img[idxs_i], training: False}\n",
    "            logit = np.concatenate((logit, sess.run(logits, feed_dict=feed_dict)), axis=0)\n",
    "\n",
    "    correct_pred = np.equal(np.argmax(logit, 1), label).astype(np.float32)\n",
    "    accuracy = np.mean(correct_pred)\n",
    "    \n",
    "    return accuracy, logit, correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'basic'\n",
    "img_row, img_col = img_train.shape[1], img_train.shape[2]\n",
    "img_depth = 1\n",
    "\n",
    "img_train = img_train.reshape(img_train.shape[0], img_row, img_col, img_depth)\n",
    "img_test = img_test.reshape(img_test.shape[0], img_row, img_col, img_depth)\n",
    "img_train = img_train.astype('float32')\n",
    "img_test = img_test.astype('float32')\n",
    "img_train /= 255\n",
    "img_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, img_row, img_col, img_depth])\n",
    "Y = tf.placeholder(tf.int64, [None])\n",
    "training = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build network\n",
    "# convolution layers\n",
    "\n",
    "block1 = Conv_block(inputs=X, filters=32, scope_num=1)\n",
    "block2 = Conv_block(inputs=block1, filters=32, scope_num=2)\n",
    "conv = Conv_block(inputs=block2, filters=32, scope_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected layers\n",
    "\n",
    "flat_num = int(conv.shape[1] * conv.shape[2] * conv.shape[3])\n",
    "flat = tf.reshape(conv, [-1, flat_num])\n",
    "\n",
    "with tf.variable_scope('{}/fc_layer'.format(model)):\n",
    "    dense1 = tf.layers.dense(inputs=flat, units=512, \n",
    "                            activation=tf.nn.relu, name='dense1')\n",
    "    drop1 = tf.layers.dropout(inputs=dense1, rate=0.25, training=training)\n",
    "    dense2 = tf.layers.dense(inputs=drop1, units=512, \n",
    "                            activation=tf.nn.relu, name='dense2')\n",
    "    drop2 = tf.layers.dropout(inputs=dense2, rate=0.25, training=training)\n",
    "    logits = tf.layers.dense(inputs=drop2, units=10, name='logit')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper prameter\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "CHECK_POINT_DIR = './save_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=tf.ConfigProto(allow_soft_placement=True)\n",
    "#config.gpu_options.allocator_type='BFC'\n",
    "config.log_device_placement=False\n",
    "config.gpu_options.allow_growth=True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find old network weights\n"
     ]
    }
   ],
   "source": [
    "# Restore and Save\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "checkpoint = tf.train.get_checkpoint_state(CHECK_POINT_DIR)\n",
    "\n",
    "if checkpoint and checkpoint.model_checkpoint_path:\n",
    "    try:\n",
    "        saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "        print(\"Successfully loaded:\", checkpoint.model_checkpoint_path)\n",
    "    except:\n",
    "        print(\"Error on loading old network weights\")\n",
    "else:\n",
    "    print(\"Could not find old network weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 23 13:43:00 2018\n",
      "Learning Started.\n",
      "=====================================\n",
      "Epoch : 01 , Cost : 0.02500\n",
      "Train Accuracy : 0.99440\n",
      "Test Accuracy : 0.99020\n",
      "Elapsed time of an epoch: 7.03070\n",
      "===========Saving network with the best accuracy===========\n",
      "=====================================\n",
      "Epoch : 02 , Cost : 0.02379\n",
      "Train Accuracy : 0.99583\n",
      "Test Accuracy : 0.99060\n",
      "Elapsed time of an epoch: 7.07181\n",
      "===========Saving network with the best accuracy===========\n",
      "=====================================\n",
      "Epoch : 03 , Cost : 0.01730\n",
      "Train Accuracy : 0.99240\n",
      "Test Accuracy : 0.98880\n",
      "Elapsed time of an epoch: 7.00362\n",
      "=====================================\n",
      "Epoch : 04 , Cost : 0.01723\n",
      "Train Accuracy : 0.99680\n",
      "Test Accuracy : 0.98940\n",
      "Elapsed time of an epoch: 6.95048\n",
      "=====================================\n",
      "Epoch : 05 , Cost : 0.01566\n",
      "Train Accuracy : 0.99577\n",
      "Test Accuracy : 0.99010\n",
      "Elapsed time of an epoch: 6.99260\n",
      "=====================================\n",
      "Final Test Accuracy : 0.99060\n",
      "Total elapsed time: 35.86638\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "print(time.asctime())\n",
    "print ('Learning Started.')\n",
    "\n",
    "total_start = time.time()\n",
    "max_accuracy = 0.0\n",
    "for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "    avg_cost = 0\n",
    "    total_batch = int(img_train.shape[0] / batch_size) + 1\n",
    "    \n",
    "    idxs = np.random.permutation(range(len(img_train)))\n",
    "    for i in range(total_batch):\n",
    "        if i < (total_batch - 1):        \n",
    "            idxs_i = idxs[i * batch_size : (i + 1) * batch_size]\n",
    "        else:\n",
    "            idxs_i = idxs[i * batch_size : len(img_train)]\n",
    "            \n",
    "        feed_dict = {X: img_train[idxs_i], Y: label_train[idxs_i], training: True}    \n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    print ('=====================================')\n",
    "    print ('Epoch : {:02d} , Cost : {:.5f}'.format(epoch + 1, avg_cost))\n",
    "    train_accuracy, _, _ = get_accuracy(sess, logits, img_train, label_train, batch_size)\n",
    "    print ('Train Accuracy : {:.5f}'.format(train_accuracy))\n",
    "    test_accuracy, _, _ = get_accuracy(sess, logits, img_test, label_test, batch_size)\n",
    "    print ('Test Accuracy : {:.5f}'.format(test_accuracy))\n",
    "    print ('Elapsed time of an epoch: {:.5f}'.format(time.time() - epoch_start))\n",
    "    if test_accuracy > max_accuracy:\n",
    "        max_accuracy = test_accuracy\n",
    "        print ('===========Saving network with the best accuracy===========')\n",
    "        if not os.path.exists(CHECK_POINT_DIR):\n",
    "            os.makedirs(CHECK_POINT_DIR)\n",
    "        saver.save(sess, CHECK_POINT_DIR + \"/model\", global_step=epoch+1)\n",
    "\n",
    "print ('=====================================')\n",
    "\n",
    "print ('Final Test Accuracy : {:.5f}'.format(max_accuracy))\n",
    "print ('Total elapsed time: {:.5f}'.format(time.time() - total_start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
